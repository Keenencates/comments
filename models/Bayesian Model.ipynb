{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Can Emoticons Be Use To Predict Sentiment\n",
    "## Keenen Cates\n",
    "### Bayesian Benchmark Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup\n",
    "\n",
    "We will first load all of the preprocessed data, and split the validation set off. Also, we will make a list of skin tone modifiers for emoticons the obfuscate the prediction (i.e. a skin tone modifier can accompany many emoticons to modify their skin tone). A deeper look will need to be done into how to deal with multi-colored hearts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from requests import get\n",
    "from os import path\n",
    "from io import BytesIO\n",
    "from zipfile import ZipFile\n",
    "from emoji_list import all_emoji\n",
    "from time import strftime\n",
    "from urllib.request import urlopen \n",
    "from collections import Counter\n",
    "from string import punctuation\n",
    "from collections import Counter\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import helper\n",
    "import math\n",
    "\n",
    "#Load comments, targets, and dictionaries for embeddings, and holdout validation data\n",
    "content, targets, emoji_to_int, int_to_emoji, vocab_to_int, int_to_vocab, token_lookup = helper.load_preprocess()\n",
    "X, Y, VAL_X, VAL_Y = helper.peel_validation(content, targets)\n",
    "skin_tones = helper.skin_tone_emojis()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building the Model\n",
    "The first step is to build our model of prior probabilities for each class and probabilities of each class relative to a given word. We could likely extend our model by changing the level at which we are modelling (i.e. N-Gram models)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generate_naive_bayes_model(model_x, model_y):\n",
    "    \"\"\" Takes a corpus of embedded comments and labels \n",
    "        and returns Naive Bayes Probabilities\n",
    "    :type model_x: List[List[Int]]\n",
    "    :type model_y: List[List[Int]]\n",
    "    :rtype       : Int, Dict, Dict, Dict, Dict\n",
    "    \"\"\"\n",
    "    n_texts = 0\n",
    "    class_dict = {emoji_to_int[k]:Counter() for k in all_emoji if k in emoji_to_int}\n",
    "    n_texts_class = {emoji_to_int[k]:1 for k in all_emoji if k in emoji_to_int}\n",
    "    \n",
    "    for i in range(len(model_x)):\n",
    "        n_texts += 1\n",
    "        for each in model_y[i]:\n",
    "            class_dict[each].update(model_x[i])\n",
    "            n_texts_class[each] += 1\n",
    "\n",
    "    rel_freq_class_dict = {emoji_to_int[k]:dict() for k in all_emoji if k in emoji_to_int}\n",
    "    \n",
    "    for class_key, counts in class_dict.items():\n",
    "        total_words = sum([val for _, val in class_dict[class_key].items()])\n",
    "        for word in counts:\n",
    "            rel_freq_class_dict[class_key][word] = class_dict[class_key][word] / total_words \n",
    "\n",
    "    prior_prob_class = {emoji_to_int[k]:n_texts_class[emoji_to_int[k]] / n_texts  for k in all_emoji if k in emoji_to_int}\n",
    "    \n",
    "    return n_texts, class_dict, n_texts_class, rel_freq_class_dict, prior_prob_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_texts, class_dict, n_texts_class, rel_freq_class_dict, prior_prob_class = generate_naive_bayes_model(X, Y)\n",
    "\n",
    "def get_rel_freq(class_key, word):\n",
    "    \"\"\"Takes a class and a word and return prob\n",
    "       of the class given the word.\n",
    "    :type class_key: Int\n",
    "    :type word     : Int\n",
    "    :rtype         : Float\n",
    "    \"\"\"\n",
    "    if word in rel_freq_class_dict[class_key]:\n",
    "        return rel_freq_class_dict[class_key][word]\n",
    "    else:\n",
    "        return .000000000001\n",
    "\n",
    "def compute_prob(class_key, text, scale = 1.0):\n",
    "    \"\"\"Computes the probability of a text having a given emoji\n",
    "    :type class_key: Int\n",
    "    :type text     : List[Int]\n",
    "    :type scale    : Float\n",
    "    :rtype         : Float\n",
    "    \"\"\"\n",
    "    prod_freqs = np.prod([get_rel_freq(class_key, word) for word in text])\n",
    "    prior = prior_prob_class[class_key]\n",
    "    return prod_freqs * (prior * scale)\n",
    "\n",
    "def create_probs(text, scale = 1.0):\n",
    "    \"\"\"Computes the probability of all classes for a given text\n",
    "    :type text     : List[Int]\n",
    "    :type scale    : Float\n",
    "    :rtype         : Float\n",
    "    \"\"\"\n",
    "    return {emoji_to_int[k]:compute_prob(emoji_to_int[k], text, scale) for k in all_emoji if k in emoji_to_int}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZUAAAEICAYAAACXo2mmAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAGulJREFUeJzt3XuYXVWd5vHvSyIgIxCQSGsSSNCAoqMtFhfbGwMDBBRC\nt0jDqAQmEmeEbm+tgO0YHi7dOmObBm2xI0QIKhAQJd2iWODtsZVLEFpEREpuSQRSEm4KgoF3/tir\n4BCrUqdO7XNODvV+nuc8tfdvr7XX2uck9au919r7yDYRERF12KTbHYiIiOeOJJWIiKhNkkpERNQm\nSSUiImqTpBIREbVJUomIiNokqURsJCR9QdL/6XY/IsZDuU8l4tkk3QlsDzzZED7X9vE1tnE08B7b\nb6xrnxEbg8nd7kDERupg21d2uxMRvSaXvyKaJOloSf8haZGkByXdLukvSnylpDWS5jWU31rSUkmD\nku6S9HFJm0h6BfAF4PWSfifpwVL+XEmnNdSfK+lGSQ9L+rWkOSX+EknLJa2VNCDp2IY6J0taVtp9\nRNLNkvoatp8gaXXZdqukfTvx3sXEkaQSMTZ7Aj8DXgh8FbgQ2B14GfAu4HOSXlDKfhbYGtgJeAtw\nFHCM7VuA/wX8xPYLbE9ZvxFJewBLgY8AU4A3A3eWzRcCq4CXAIcB/yBpn4bqh5QyU4DlwOfKPncB\njgd2t70lcEDDPiNqkaQSMbxvlLORodfQ2cAdtr9k+0ngImAGcIrtx21/B3gCeJmkScARwEm2H7F9\nJ/BPwLubbH8+sMR2v+2nbK+2/UtJM4A3ACfY/oPtG4GzqRLWkB/Zvrz08XzgNSX+JLAZsKuk59m+\n0/avW3x/IoaVpBIxvENtT2l4fbHE72so8xiA7fVjLwC2A54H3NWw7S5gWpPtzwCG+4X/EmCt7Uc2\nsN97G5YfBTaXNNn2APAB4GRgjaQLJb2kyf5ENCVJJaI9fgv8EdixIbYDsLosjzbtciXw0mHivwG2\nlbTlCPvdINtfLTPOdix9+FQz9SKalaQS0Qbl0tMy4HRJW0raEfgQ8OVS5D5guqRNR9jFOcAxkvYt\ng/vTJL3c9krgx8A/Stpc0qupLpV9eYT9PE3SLpL2kbQZ8Aeqs6qnxnWgEetJUokY3r+VmVlDr6+3\nsI+/AX4P3A78iGpgf0nZ9l3gZuBeSb9dv6Lta4FjgEXAQ8APeOas50hgJtVZy9eBhU1Of94M+CTV\nWdS9wIuAk1o4rogR5ebHiIioTc5UIiKiNkkqERFRmySViIioTduSiqQl5bEVPx9m24clWdJ2ZV2S\nziyPnPiZpN0ays6TdFt5NT4C43WSbip1zpSkdh1LREQ0p50PlDyX6vEQSxuD5Y7g/YG7G8IHArPL\na0/gLGBPSdsCC4E+qjn110tabvuBUuZY4BrgcmAO8K3ROrXddtt55syZ4zmuiIgJ5/rrr/+t7amj\nlWtbUrH9Q0kzh9m0CPgocFlDbC6w1NVUtKslTZH0YmBvoN/2WgBJ/cAcSd8HtrJ9dYkvBQ6liaQy\nc+ZMVqxY0ephRURMSJLuGr1Uh8dUJM0FVtv+z/U2TaO6g3jIqhLbUHzVMPGR2l0gaYWkFYODg+M4\ngoiI2JCOJRVJWwAfAz7RqTaH2F5su89239Spo569RUREizp5pvJSYBbwn+Wb9aYDP5X0Z1TPLZrR\nUHZ6iW0oPn2YeEREdFHHkortm2y/yPZM2zOpLlntZvtequ98OKrMAtsLeMj2PcAVwP6StpG0DdUA\n/xVl28OS9iqzvo7i2WM0ERHRBe2cUnwB8BNgF0mrJM3fQPHLqZ6PNAB8EXgfQBmgPxW4rrxOGRq0\nL2XOLnV+TROD9BER0V4T7tlffX19zuyviIixkXS97b7RyuWO+oiIqE2SSkRE1CZJJSIiatPOx7Q8\n5yzq/9WYyn9wv53b1JOIiI1TzlQiIqI2SSoREVGbJJWIiKhNkkpERNQmSSUiImqTpBIREbVJUomI\niNokqURERG2SVCIiojZJKhERUZsklYiIqE2SSkRE1CZJJSIiapOkEhERtUlSiYiI2iSpREREbZJU\nIiKiNkkqERFRm7YlFUlLJK2R9POG2P+T9EtJP5P0dUlTGradJGlA0q2SDmiIzymxAUknNsRnSbqm\nxC+StGm7jiUiIprTzjOVc4E568X6gVfZfjXwK+AkAEm7AkcAryx1Pi9pkqRJwL8ABwK7AkeWsgCf\nAhbZfhnwADC/jccSERFNaFtSsf1DYO16se/YXldWrwaml+W5wIW2H7d9BzAA7FFeA7Zvt/0EcCEw\nV5KAfYBLSv3zgEPbdSwREdGcbo6p/E/gW2V5GrCyYduqEhsp/kLgwYYENRQflqQFklZIWjE4OFhT\n9yMiYn1dSSqS/h5YB3ylE+3ZXmy7z3bf1KlTO9FkRMSENLnTDUo6GngbsK9tl/BqYEZDseklxgjx\n+4EpkiaXs5XG8hulRf2/GnOdD+63cxt6EhHRPh09U5E0B/gocIjtRxs2LQeOkLSZpFnAbOBa4Dpg\ndpnptSnVYP7ykoy+BxxW6s8DLuvUcURExPDaOaX4AuAnwC6SVkmaD3wO2BLol3SjpC8A2L4ZWAb8\nAvg2cJztJ8tZyPHAFcAtwLJSFuAE4EOSBqjGWM5p17FERERz2nb5y/aRw4RH/MVv+3Tg9GHilwOX\nDxO/nWp2WEREbCRyR31ERNQmSSUiImqTpBIREbVJUomIiNokqURERG2SVCIiojZJKhERUZsklYiI\nqE2SSkRE1CZJJSIiapOkEhERtUlSiYiI2iSpREREbZJUIiKiNkkqERFRmySViIioTZJKRETUJkkl\nIiJqk6QSERG1SVKJiIjaJKlERERtJne7A9GcRf2/GlP5D+63c5t6EhExsradqUhaImmNpJ83xLaV\n1C/ptvJzmxKXpDMlDUj6maTdGurMK+VvkzSvIf46STeVOmdKUruOJSIimtPOy1/nAnPWi50IXGV7\nNnBVWQc4EJhdXguAs6BKQsBCYE9gD2DhUCIqZY5tqLd+WxER0WFtSyq2fwisXS88FzivLJ8HHNoQ\nX+rK1cAUSS8GDgD6ba+1/QDQD8wp27ayfbVtA0sb9hUREV3S6YH67W3fU5bvBbYvy9OAlQ3lVpXY\nhuKrhokPS9ICSSskrRgcHBzfEURExIi6NvurnGG4Q20ttt1nu2/q1KmdaDIiYkLqdFK5r1y6ovxc\nU+KrgRkN5aaX2Ibi04eJR0REF3U6qSwHhmZwzQMua4gfVWaB7QU8VC6TXQHsL2mbMkC/P3BF2faw\npL3KrK+jGvYVERFd0rb7VCRdAOwNbCdpFdUsrk8CyyTNB+4CDi/FLwcOAgaAR4FjAGyvlXQqcF0p\nd4rtocH/91HNMHs+8K3yioiILmpbUrF95Aib9h2mrIHjRtjPEmDJMPEVwKvG08eIiKhXHtMSERG1\nSVKJiIjaJKlERERtklQiIqI2SSoREVGbJJWIiKhNkkpERNQmSSUiImqTpBIREbVJUomIiNrkO+on\ngHy/fUR0Ss5UIiKiNkkqERFRmySViIioTZJKRETUpqmkIum/trsjERHR+5o9U/m8pGslvU/S1m3t\nUURE9KymkortNwHvBGYA10v6qqT92tqziIjoOU2Pqdi+Dfg4cALwFuBMSb+U9Fft6lxERPSWZsdU\nXi1pEXALsA9wsO1XlOVFbexfRET0kGbvqP8scDbwMduPDQVt/0bSx9vSs4iI6DnNJpW3Ao/ZfhJA\n0ibA5rYftX1+23oXERE9pdkxlSuB5zesb1FiLZH0QUk3S/q5pAskbS5plqRrJA1IukjSpqXsZmV9\noGyf2bCfk0r8VkkHtNqfiIioR7NJZXPbvxtaKctbtNKgpGnA3wJ9tl8FTAKOAD4FLLL9MuABYH6p\nMh94oMQXlXJI2rXUeyUwh2ra86RW+hQREfVoNqn8XtJuQyuSXgc8toHyo5kMPF/SZKrkdA/VoP8l\nZft5wKFleW5Zp2zfV5JK/ELbj9u+AxgA9hhHnyIiYpyaHVP5AHCxpN8AAv4M+OtWGrS9WtKngbup\nEtN3gOuBB22vK8VWAdPK8jRgZam7TtJDwAtL/OqGXTfWeRZJC4AFADvssEMr3Y6IiCY0lVRsXyfp\n5cAuJXSr7T+20qCkbajOMmYBDwIXU12+ahvbi4HFAH19fW5nWxERE9lYvqRrd2BmqbObJGwvbaHN\n/w7cYXsQQNKlwBuAKZIml7OV6cDqUn411Z38q8rlsq2B+xviQxrrREREFzR78+P5wKeBN1Ill92B\nvhbbvBvYS9IWZWxkX+AXwPeAw0qZecBlZXl5Wads/65tl/gRZXbYLGA2cG2LfYqIiBo0e6bSB+xa\nfpmPi+1rJF0C/BRYB9xAdWnqm8CFkk4rsXNKlXOA8yUNAGupZnxh+2ZJy6gS0jrguKH7aCIiojua\nTSo/pxqcv6eORm0vBBauF76dYWZv2f4D8I4R9nM6cHodfYqIiPFrNqlsB/xC0rXA40NB24e0pVcR\nEdGTmk0qJ7ezExER8dzQ7JTiH0jaEZht+0pJW1DdCR8REfG0Zmd/HUt1N/u/ltA04Bvt6lRERPSm\nZh/TchzVvSQPw9Nf2PWidnUqIiJ6U7NJ5XHbTwytlJsQc2d6REQ8S7NJ5QeSPkb1EMj9qB6t8m/t\n61ZERPSiZpPKicAgcBPwXuByqu+rj4iIeFqzs7+eAr5YXhEREcNqKqlIuoNhxlBs71R7jyIiomeN\n5dlfQzanemzKtvV3JyIiellTYyq27294rbb9z8Bb29y3iIjoMc1e/tqtYXUTqjOXsXwXS0RETADN\nJoZ/alheB9wJHF57byIioqc1O/vrv7W7IxER0fuavfz1oQ1tt/2ZeroTERG9bCyzv3an+gpfgIOp\nvrr3tnZ0KiIielOzSWU6sJvtRwAknQx80/a72tWxiIjoPc0+pmV74ImG9SdKLCIi4mnNnqksBa6V\n9PWyfihwXnu6FBERvarZ2V+nS/oW8KYSOsb2De3rVkRE9KJmL38BbAE8bPsMYJWkWa02KmmKpEsk\n/VLSLZJeL2lbSf2Sbis/tyllJelMSQOSftZ4I6akeaX8bZLmtdqfiIioR7NfJ7wQOAE4qYSeB3x5\nHO2eAXzb9suB1wC3UD1e/yrbs4GryjrAgcDs8loAnFX6tC2wENgT2ANYOJSIIiKiO5o9U/lL4BDg\n9wC2fwNs2UqDkrYG3gycU/b1hO0Hgbk8M05zHtW4DSW+1JWrgSmSXgwcAPTbXmv7AaAfmNNKnyIi\noh7NJpUnbJvy+HtJ/2Ucbc6i+sKvL0m6QdLZZX/b276nlLmXZ2aXTQNWNtRfVWIjxf+EpAWSVkha\nMTg4OI6uR0TEhjSbVJZJ+leqs4RjgStp/Qu7JgO7AWfZfi3V2c+JjQUaE1gdbC+23We7b+rUqXXt\nNiIi1tPso+8/DVwCfA3YBfiE7c+22OYqYJXta8r6JVRJ5r5yWYvyc03ZvhqY0VB/eomNFI+IiC4Z\nNalImiTpe7b7bX/E9t/Z7m+1Qdv3Aisl7VJC+wK/oHoEzNAMrnnAZWV5OXBUmQW2F/BQuUx2BbC/\npG3KAP3+JRYREV0y6n0qtp+U9JSkrW0/VFO7fwN8RdKmwO3AMVQJbpmk+cBdPPNo/cuBg4AB4NFS\nFttrJZ0KXFfKnWJ7bU39i4iIFjR7R/3vgJsk9VNmgAHY/ttWGrV9I8/+iuIh+w5T1sBxI+xnCbCk\nlT5ERET9mk0ql5ZXRETEiDaYVCTtYPtu23nOV0REjGq0gfpvDC1I+lqb+xIRET1utKSihuWd2tmR\niIjofaMlFY+wHBER8SdGG6h/jaSHqc5Ynl+WKeu2vVVbexcRET1lg0nF9qROdSQiInrfWL5PJSIi\nYoOSVCIiojZJKhERUZsklYiIqE2SSkRE1CZJJSIiapOkEhERtUlSiYiI2iSpREREbZJUIiKiNkkq\nERFRmySViIioTZJKRETUJkklIiJqk6QSERG16VpSkTRJ0g2S/r2sz5J0jaQBSRdJ2rTENyvrA2X7\nzIZ9nFTit0o6oDtHEhERQ7p5pvJ+4JaG9U8Bi2y/DHgAmF/i84EHSnxRKYekXYEjgFcCc4DPS8qX\nikVEdFFXkoqk6cBbgbPLuoB9gEtKkfOAQ8vy3LJO2b5vKT8XuND247bvAAaAPTpzBBERMZxunan8\nM/BR4Kmy/kLgQdvryvoqYFpZngasBCjbHyrln44PU+dZJC2QtELSisHBwTqPIyIiGnQ8qUh6G7DG\n9vWdatP2Ytt9tvumTp3aqWYjIiacyV1o8w3AIZIOAjYHtgLOAKZImlzORqYDq0v51cAMYJWkycDW\nwP0N8SGNdSIiogs6fqZi+yTb023PpBpo/67tdwLfAw4rxeYBl5Xl5WWdsv27tl3iR5TZYbOA2cC1\nHTqMiIgYRjfOVEZyAnChpNOAG4BzSvwc4HxJA8BaqkSE7ZslLQN+AawDjrP9ZOe7HRERQ7qaVGx/\nH/h+Wb6dYWZv2f4D8I4R6p8OnN6+HkZExFjkjvqIiKhNkkpERNQmSSUiImqTpBIREbVJUomIiNps\nTFOKYyO0qP9XY67zwf12bkNPIqIX5EwlIiJqk6QSERG1SVKJiIjaJKlERERtklQiIqI2SSoREVGb\nJJWIiKhNkkpERNQmSSUiImqTpBIREbVJUomIiNokqURERG3yQMloq7E+kDIPo4zobUkqsdFKQoro\nPbn8FRERtUlSiYiI2nT88pekGcBSYHvAwGLbZ0jaFrgImAncCRxu+wFJAs4ADgIeBY62/dOyr3nA\nx8uuT7N9XiePJTZu47l8lktvEa3pxpnKOuDDtncF9gKOk7QrcCJwle3ZwFVlHeBAYHZ5LQDOAihJ\naCGwJ7AHsFDSNp08kIiIeLaOn6nYvge4pyw/IukWYBowF9i7FDsP+D5wQokvtW3gaklTJL24lO23\nvRZAUj8wB7igYwcTMYx8BXNMZF0dU5E0E3gtcA2wfUk4APdSXR6DKuGsbKi2qsRGig/XzgJJKySt\nGBwcrK3/ERHxbF1LKpJeAHwN+IDthxu3lbMS19WW7cW2+2z3TZ06ta7dRkTEerqSVCQ9jyqhfMX2\npSV8X7msRfm5psRXAzMaqk8vsZHiERHRJR1PKmU21znALbY/07BpOTCvLM8DLmuIH6XKXsBD5TLZ\nFcD+krYpA/T7l1hERHRJN+6ofwPwbuAmSTeW2MeATwLLJM0H7gIOL9sup5pOPEA1pfgYANtrJZ0K\nXFfKnTI0aB8xUWUqdHRbN2Z//QjQCJv3Haa8geNG2NcSYEl9vYvoviSG6GV59ldEAJkKHfXIY1oi\nIqI2OVOJiFrksl1AzlQiIqJGSSoREVGbXP6KiJ6WCQYblySViOi6bo7HdPIrEtav/1yUy18REVGb\nnKlERHTJc3HGXJJKREQP2lgTUi5/RUREbZJUIiKiNkkqERFRmySViIioTZJKRETUJkklIiJqk6QS\nERG1SVKJiIjaJKlERERtklQiIqI2SSoREVGbJJWIiKhNzycVSXMk3SppQNKJ3e5PRMRE1tNJRdIk\n4F+AA4FdgSMl7drdXkVETFw9nVSAPYAB27fbfgK4EJjb5T5FRExYst3tPrRM0mHAHNvvKevvBva0\nffx65RYAC8rqLsCtNXdlO+C3Xag7UdtOvydO2+l359seyY62p45WaEJ8SZftxcDidu1f0grbfZ2u\nO1HbTr8nTtvpd+fbHq9ev/y1GpjRsD69xCIiogt6PalcB8yWNEvSpsARwPIu9ykiYsLq6ctfttdJ\nOh64ApgELLF9cxe6Mp5La+O9LDcR206/J07b6Xfn2x6Xnh6oj4iIjUuvX/6KiIiNSJJKRETUpqfH\nVLpN0tuAD1C9j5vYfnOH2p0OnAq8FHiS6jLm3h1q+23A+3nmmN/SiXa7abzvdzc/rxib8pSO1wG/\ntn2/pO2A2bZ/0mT9Cf9ZJ6m0SNIHgFcDb7f9UAv1/5zqiQCXAYPAXwKTbC8bpd5OwLnA+23fUGLP\nH2v7rSjHPAs43PYDLdQ/GdgLWFdCk4GrbZ/c7vqt1h3v+11D/Zb6XUf9btXtctuXAIcC90p6K3Al\nsA2gJtrt2c+6VrbzGuML2An4JvAu4KfAK4EPj6H+7uWDN3A3cGZZdhN1L6b6S+pa4BrgvcAPOnTM\n5wM7At+getbaO8e4j5OBKQ3rU4CTO1G/1brl/d6hvOcvBDYFFo2hz0Of138Afw/sDFzzXH7PerXf\npZwbXiub/X/Z6591na+MqbTmYKq/AnYBDqf6BbvpGOrvTjUFGqqbN9/bTCVJWwGP2L6e6h/894Dv\nUP3Cb7eDqc7MtqI6rf8j8FgH2u2ahvf7bqr/sPsBrwdePpb6wGbASVTv2yuAo9vQ3Ri/h4D7Gtan\nN1sxn/UzcvlrjMo/nrcAZwAfBd7UsPkfm9zNRcA8qstf8ExC+v0o9bYD7i3L7wb+YPspSa9ost2W\nNBzzAts3SVoGLKG6bHdpO9vusqffb9sHS5pJ9ZktGkt92z8u6z+su4NRH9uW9FHgvBaqD/1bmQvs\nWWJzys+9x9+73pEzlbHbG1gFbAmsofrF+iOqAfum2L4feAPwCaq/aKD6hfPKUareA+wk6cXAfraf\nKvF2/3GwN3AXMEvSHsAFwBupxoGey+7h2WeBq4HPAP9jLPUlbS9p76Fgp8bAYuxsL+VPbx78TBNV\nh/6tPAw8AZwGrKD6XTGh5ExljGwvl3Ql1fXTM4B/ADYHngfcOIb9rANOlTQAHEk14P/HUeo8JulB\nqpklfy7pSKpT9m2Bd7RyPE32dbmkfqpjvpsmBi2fC4beb0l/Uc42dqJK/ieMpT7VZdKDJB0D3E81\nLvX2dvU7xu14qkvab6QaO/3IaBUaPuurgX2Av6L697JlG/u5UUpSaYHtRyWdRjV18FSqX7LrNlxr\nxH1dIOmS0RJKg49Q/XK/lCqpraMaEGyr8p/mFOB04M3Aj6mS6XPdR4CLJV1K9X097wRey7OvvY9a\nn+rz+r9UA787tqGfURPbf5T0dqqZXEc2XBEYzdBnPfTH1+Y8x8cdh5PLXy1yNW/9GKoxleOB941j\nX80mFGw/AhxCNdB/PtUDNN/TattjYftaqmM+hOp5axd3ot1uWu/9/gpwFWN4v9er/yWq96wjn1e0\nzvYa2weVz6/ZOkOftYD/TfV74eA2dXGjlTOVcbC9Evi7LrT7BHBWeXW67VU0cTlgBGuApZKG/vLb\nBPh2h+q3XHe87/c46/fkezbOut1uu2U9/FnXJg+UjIiI2uTyV0RE1CZJJSIiapOkEhERtUlSiYiI\n2iSpREREbf4/ELOmAnzhzxMAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f3796601978>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "hist = [(int_to_emoji[k], v) for k, v in n_texts_class.items()][:20]\n",
    "emoticons = []\n",
    "counts = []\n",
    "for k, v in hist:\n",
    "    emoticons.append(k)\n",
    "    counts.append(v)\n",
    "y_pos = np.arange(len(emoticons))\n",
    "\n",
    "plt.bar(y_pos, counts, align='center', alpha=0.5)\n",
    "plt.xticks(y_pos, emoticons)\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Emoticons')\n",
    " \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Making Predictions\n",
    "We will make predictions make selecting the top k most likely classes. This is because there is some ambiguity to emoticons, i.e. there are multiple types of hearts and smiley faces with hearts. That means that multiple classes could be appropriate for a given text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def top_k_predictions(text, k, preprocess=False, scale = 1.0):\n",
    "    \"\"\"Computes the top k most probable classes\n",
    "    :type text      : List[Int]\n",
    "    :type k         : Int\n",
    "    :type preprocess: Boolean\n",
    "    :type scale     : Float\n",
    "    :rtype          : List[Int]\n",
    "    \"\"\"\n",
    "    if preprocess:\n",
    "        text = helper.tokenize_and_embed(text, token_lookup, vocab_to_int)\n",
    "    probs = create_probs(text, scale)\n",
    "    probs = {k:v for k, v in probs.items()}\n",
    "    probs = probs.items()\n",
    "    sorted_probs = sorted(probs, key=lambda x: x[1], reverse=True)\n",
    "    \n",
    "    res = []\n",
    "    idx = 0\n",
    "    while len(res) < k:\n",
    "        #We want to ignore the skin tone modifiers\n",
    "        if int_to_emoji[sorted_probs[idx][0]] not in skin_tones:\n",
    "            res.append(sorted_probs[idx][0])\n",
    "        idx += 1\n",
    "    return res\n",
    "\n",
    "def dummy_top_k_predict(x, k):\n",
    "    \"\"\"Predicts the top k most frequent classes\n",
    "    :type x: List[Int]\n",
    "    :type k: Int\n",
    "    :rtype : List[Int]\n",
    "    \"\"\"\n",
    "    classes = prior_prob_class.items()\n",
    "    classes = sorted(classes, key = lambda x: x[1], reverse = True)\n",
    "    return [classes[i][0] for i in range(0, k)]\n",
    "\n",
    "def print_nth_prediction(text_n, scale=1.0):\n",
    "    \"\"\"Prints a nicely formatted chart for comparing results\n",
    "    :type text      : List[Int]\n",
    "    :type scale     : Float\n",
    "    \"\"\"\n",
    "    print('Comment     :', helper.get_nth_text(content, int_to_vocab, text_n))\n",
    "    print('Emoticons   :', helper.get_nth_label(targets, int_to_emoji, text_n))\n",
    "    print('Top 5 Preds :', ' '.join(int_to_emoji[each] for each in top_k_predictions(content[text_n], 5, scale = scale)))\n",
    "    print('Dummy Pred  :', ' '.join(int_to_emoji[each] for each in dummy_top_k_predict(content[text_n], 5)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Examples\n",
    "Here are some examples of the Models Prediction!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0, 100, 5):\n",
    "    print_nth_prediction(i)\n",
    "    print('-' * 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Validation\n",
    "\n",
    "Finally we test our model! It appears that the model is having some problems generalizing. I am inclined to think the N-gram models could help us improve our generality. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Bayesian Training Accuracy :', helper.top_k_categorical_accuracy(X, Y, top_k_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Dummy Training Accuracy    :', helper.top_k_categorical_accuracy(X, Y, dummy_top_k_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Bayesian Validation Accuracy :', helper.top_k_categorical_accuracy(VAL_X, VAL_Y, top_k_predictions))\n",
    "print('Dummy Validation Accuracy    :', helper.top_k_categorical_accuracy(VAL_X, VAL_Y, dummy_top_k_predict))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
